# -*- coding: utf-8 -*-
"""Projekt-hokej.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cjJVtAmhM2cq4nS7c3T3sFt6Fy3xkiYz
"""

!pip install beautifulsoup4 requests
!pip install cx_Oracle --upgrade --pre

!pip install requests
!pip install beautifulsoup4

import requests
from bs4 import BeautifulSoup
import pandas as pd

# Adres URL strony z danymi
url = "https://www.hockey-reference.com/leagues/NHL_2024_standings.html"

# Pobieranie zawartości strony
response = requests.get(url)

# Parsowanie zawartości HTML strony
soup = BeautifulSoup(response.content, 'html.parser')

# Znalezienie wszystkich tabel na stronie
tables = soup.find_all('table')

# Wyciąganie danych z Tabeli 3
table3 = tables[2]  # Trzecia tabela (indeks 2)

# Zbieranie danych z Tabeli 3
rows = table3.find_all('tr')
table3_data = []
for row in rows[1:]:  # Pomijamy pierwszy wiersz nagłówka
    cells = row.find_all(['th', 'td'])
    table3_data.append([cell.text.strip() for cell in cells])

# Konwertowanie danych do DataFrame
columns_table3 = [cell.text.strip() for cell in rows[0].find_all(['th', 'td'])]
df_table3 = pd.DataFrame(table3_data, columns=columns_table3)

# Wyciąganie danych z Tabeli 4
table4 = tables[3]  # Czwarta tabela (indeks 3)

# Zbieranie danych z Tabeli 4
rows = table4.find_all('tr')
table4_data = []
for row in rows[1:]:  # Pomijamy pierwszy wiersz nagłówka
    cells = row.find_all(['th', 'td'])
    table4_data.append([cell.text.strip() for cell in cells])

# Konwertowanie danych do DataFrame
columns_table4 = [cell.text.strip() for cell in rows[0].find_all(['th', 'td'])]
df_table4 = pd.DataFrame(table4_data, columns=columns_table4)

# Wyświetlenie danych z Tabeli 3
print("Tabela 3:")
print(df_table3)

# Wyświetlenie danych z Tabeli 4
print("\nTabela 4:")
print(df_table4)

# Zapisywanie danych do plików CSV (opcjonalnie)
df_table3.to_csv('table3_data.csv', index=False)
df_table4.to_csv('table4_data.csv', index=False)